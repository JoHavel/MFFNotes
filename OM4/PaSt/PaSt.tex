\documentclass[12pt]{article}					% Začátek dokumentu
\usepackage{../../MFFStyle}					    % Import stylu



\begin{document}

% 14. 02. 2022
\section*{Organizační úvod}
\begin{poznamka}
	Podmínkou zápočtu je splnění 1 domácí práce a 1 písemného testu. Není potřeba docházka.

	Bude moodle (přístup dají cvičící). Budou tam poznámky k přednášce, cvičebnice a bude se tam odevzdávat domácí práce.

	Je dobré umět míru.
\end{poznamka}

\section{Úvod}
\begin{poznamka}
	Pravděpodobnost popisuje modely popisující náhodné jevy.

	Statistika se pak snaží popsat reálné věci za pomocí těchto modelů.
\end{poznamka}

\begin{poznamka}[Historie]
	Klasická pravděpodobnost navazuje na dílo Kolmogorova, který popisoval axiomatickou pravděpodobnost.
\end{poznamka}

\section{Pravděpodobnostní prostor}
\begin{definice}[Pravděpodobnostní prostor, pravděpodobnost]
	Pravděpodobnostní prostor je trojice $(\Omega, ©A, P)$, kde $\Omega$ je neprázdná množina, ©A je $\sigma$-algebra a $P$ je pravděpodobnost.

	Pravděpodobnost $P$ je množinová funkce $©A \rightarrow [0, 1]$ splňující:
	\begin{itemize}
		\item $P(A) ≥ 0\ \forall A \in ©A$, (nezápornost)
		\item $P(\Omega) = 1$, (normovanost)
		\item jsou-li $A_i \in ©A$ po dvou disjunktní, pak $P\(\bigcup_{i=1}^∞ A_i\) = \sum_{i=1}^∞ P(A_i)$. ($\sigma$-aditivita)
	\end{itemize}
	
	\begin{poznamkain}[Interpretace]
		$\Omega$ se často nazývá stavový prostor a obsahuje všechny „realizace náhody“ neboli elementární jevy, tj. všechny možnosti, o kterých uvažuji.

		©A je $\sigma$-algebra náhodných jevů. $P$ pak obsahuje veškerou informaci o té dané náhodné situaci.

		Pokud nastal $\omega \in A \in ©A$ ($\omega \in \Omega$), pak nastal jev $A$.
	\end{poznamkain}

	\begin{definicein}[Klasický pravděpodobnostní prostor, diskrétní pravděpodobnostní prostor, spojitý pravděpodobnostní prostor, indikátor]
		$\Omega$ konečná, $©A = 2^\Omega$, $P(\{a\}) = \frac{1}{n}\ \forall a \in \Omega$ je klasický pravděpodobnostní prostor.

		$\Omega$ spočetná (včetně konečná), $©A = 2^\Omega$, $p: \Omega \rightarrow [0, 1]$ je taková, že $p(\omega) ≥ 0\ \forall \omega \in \Omega$ a $\sum_{\omega \in \Omega} = 1$. Položíme $P(A) = \sum_{\omega \in A} p(\omega)\ \forall A \in ©A$ nazýváme diskrétní pravděpodobnostní prostor.

		$\Omega = ®R$, $©A = ©B(®R)$ (resp. $©B_0(®R)$) a $g: ®R \rightarrow [0, ∞)$ měřitelná, že $\int_{®R} g(x) dx = 1$, pak definujeme $P(B) = \int_B g(x) dx$, $b \in ©B(®R) = ©A$ je spojitý pravděpodobnostní prostor. Speciálním případem $g(x) = 1_{[0, 1]}(x)$ je pak tzv. indikátor.
	\end{definicein}
\end{definice}

\begin{definice}[Jev jistý, jev nemožný, podjev, zároveň, alespoň jeden, jev opačný, neslučitelné jevy]
	$\Omega$ je jev jistý, $\O$ je jev nemožný, $A \subset B$ znamená „$A$ je podjev $B$“, $A \cap B$ znamená „nastal $A$ a zároveň $B$“, $A \cup B$ znamená „nastal $A$ nebo $B$“, $A^C$ je jev opačný, $A \cap B = \O$ jsou neslučitelné jevy.
\end{definice}

\begin{veta}
	Buďte $(\Omega, ©A, P)$ pravděpodobnostní prostor a $A, B, A_i \in ©A$ ($i \in ®N$) náhodné jevy. Pak platí:
	\begin{itemize}
		\item $P(\O) = 0$;
		\item $P$ je konečně aditivní;
		\item $P(A^C) = 1 - P(A)$;
		\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$;
		\item $A \subset B \implies P(A) ≤ P(B)$; (monotonie)
		\item $A_1 \subseteq A_2 \subseteq … \implies P\(\bigcup_{i=1}^∞ A_i\) = \lim_{n \rightarrow ∞} P(A_i)$; (spojitost)
		\item $A_1 \supseteq A_2 \supseteq … \implies P\(\bigcap_{i=1}^∞ A_i\) = \lim_{n \rightarrow ∞} P(A_i)$; (spojitost)
		\item $A_1 \supseteq A_2 \supseteq … \land \bigcap_{i=1}^∞ A_i = \O \implies \lim_{n \rightarrow ∞} P(A_i) = 0$; (spojitost v nule)
		\item $B \subset A \implies P(A \setminus B) = P(A) - P(B)$.
	\end{itemize}

	\begin{dukazin}
		Vše z míry. Pravdědobnost je konečná, předposlední bod vyplývá z předchozího.
	\end{dukazin}
\end{veta}

% 16. 02. 2022

\begin{poznamka}
	28. února bude v 17:20 náhradní přednáška za poslední přednášku.
\end{poznamka}

\begin{veta}[Princip inkluze a exkluze]
	Buď $(\Omega, ©A, P)$ pravděpodobnostní prostor. Pak pro každé $n \in ®N$ a každá $A_i \in ©A$, $i \in ®N$, platí:
	$$ P(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n P(A_i) - \sum_{1 ≤ i ≤ j ≤ n} P(A_i \cap A_j) + … + (-1)^{n-1} P(\bigcap_{i=1}^n A_i). $$

	\begin{dukazin}
		Nebude, v podstatě byl v diskrétce.
	\end{dukazin}
\end{veta}

\section{Podmíněná pravděpodobnost}
\begin{definice}[Podmíněná pravděpodobnost]
	Buďte $A, B \in ©A$ takové, že $P(B) > 0$. Definujeme $P(A|B) = \frac{P(A \cap B)}{P(B)}$ a nazýváme ji podmíněnou pravděpodobností jevu $A$ za podmínky (jevu) $B$.
\end{definice}

\begin{veta}
	Buď $B \in ©A$ takové, že $P(B) > 0$. Pak zobrazení $P(.|B): ©A \rightarrow [0, 1]$ splňuje definici pravděpodobnosti.

	\begin{dukazin}
		Ověříme po bodech: zřejmě $P(A|B) ≥ 0$ $\forall A \in ©A$, $P(\Omega|B) = \frac{P(\Omega \cap B)}{P(B)} = \frac{P(B)}{P(B)} = 1$ a $\sigma$-aditivita plyne ze $\sigma$-aditivity $P(. \cap B)$ a deMorganových pravidel ($B \cap \bigcup_{i=1}^∞ A_i = \bigcup_{i=1}^∞ A_i \cap B$), $P(B)^{-1}$ se prostě z obou stran vytkne.
	\end{dukazin}
\end{veta}

\begin{upozorneni}
	Podmíněná pravděpodobnost nám neříká nic o příčinné souvislosti.
\end{upozorneni}

\begin{pozorovani}[O podmíněné pravděpodobnosti]
	Buďte $A, B, C \in ©A$ a pravděpodobnost „správných“ jevů nenulová. Pak:
	
	\begin{itemize}
		\item $P(A \cup B | C) = P(A|C) + P(B|C) - P(A \cap B|C)$,
		\item $B \subset A \implies P(A|B) = 1$,
		\item $A \cap B = \O \implies P(A|B) = 0$,
		\item $P(A | \Omega) = P(A)$,
		\item pokud $P(\{\omega\}) > 0$, pak $\forall A \in ©A$ platí $P(A|\{\omega\}) = \delta_{\omega}(A)$.
	\end{itemize}

	\begin{dukazin}
		Triviální (buď z definice, nebo z toho, že je to pravděpodobnost).
	\end{dukazin}
\end{pozorovani}

\begin{upozorneni}[Neplatí!]
	$P(A | B \cup C) = P(A|B) + P(A|C)$, ani v případě, že $A \cap B = \O$.
\end{upozorneni}

\begin{veta}[O násobení pravděpodobností]
	Buďte $A_1, A_2, …, A_n \in ©A$ takové, že $P(A_1 \cap A_2 \cap … \cap A_{n-1}) > 0$. Pak
	$$ \hspace{-0.3em}P(A_1 \cap A_2 \cap … \cap A_n) = P(A_n | A_1 \cap … \cap A_{n-1}) · P(A_{n-1} | A_1 \cap A_2 \cap … \cap A_{n-2}) · … · P(A_2 | A_1) · P(A_1).\hspace{-0.3em} $$

	\begin{dukazin}
		Z $P(A_1 \cap … \cap A_{n-1}) > 0$ plyne, že $P(A_1 \cap … \cap A_k) > 0$ pro $k \in [n-1]$, pomocí monotonie pravděpodobnosti. Tedy výraz je dobře definován.

		Dokážeme indukcí: Pro $n = 2$ platí $P(A_1 \cap A_2) = P(A_2|A_1)·P(A_1)$ z definice. Z $n-1$ na $n$: ($B := A_1 \cap … \cap A_{n-1}$)
		$$ P(A_1 \cap A_2 \cap … \cap A_n) = P(B \cap A_n) \overset{\text{def}}= P(A|B)·P(B) \overset{\text{IP}}= $$
		$$ = P(A_n | A_1 \cap … \cap A_{n-1}) · P(A_{n-1} | A_1 \cap A_2 \cap … \cap A_{n-2}) · … · P(A_2 | A_1) · P(A_1). $$
	\end{dukazin}
\end{veta}

\begin{veta}[O celkové pravděpodobnosti]
	Buďte $A, B_1, B_2, …$ náhodné jevy takové, že $P(\bigcup_n B_n) = 1$ a $B_i \cap B_j = \O$ $\forall i ≠ j$ a $P(B_i) > 0\ \forall i$. Potom $P(A) = \sum_n P(A | B_n)·P(B_n)$.
	
	\begin{dukazin}
		Víme $P\(\(\bigcup_n B_n\)^c\) = 0$, a tedy $P(A) = P\(A \cap \bigcup_n B_n\) + P\(A \cap \(\bigcup_n B_n\)\) = P\(A \cap \bigcup_n B_n\)$, protože $P$ je konečně-aditivní a platí monotonie. Dle de Morganových pravidel (a toho, že průnik s další množinou zachovává disjunktnost):
		$$ P(A) = P\(\bigcup_n(A \cap B_n)\) = \sum_n P(A \cap B_n) = \sum_n P(A|B_n) · P(B_n). $$
	\end{dukazin}
\end{veta}

\begin{veta}[Bayesova]
	Za předpokladů věty o celkové pravděpodobnosti a $P(A) > 0$, platí $P(B_i|A) = \frac{P(A|B_i)P(B_i)}{\sum_n P(A|B_n)P(B_n)}$.

	\begin{dukazin}
		Snadný z definice podmíněné pravděpodobnosti a věty o celkové pravděpodobnosti.
	\end{dukazin}
\end{veta}

\begin{priklad}[Pólyovo urnové schéma]
	Máme v urně $n$ koulí $k$ různých barev. Náhodně taháme z urny. Po vytažení koule do urny vytaženou kouli vrátíme a s ní i $\Delta$ (pevný parametr) koulí stejné barvy.

	Podle volby $\Delta$ máme 2 základní schémata: $\Delta = -1$ (tahání bez vracení) a $\Delta = 0$ (tahání s vracením).
\end{priklad}

% 21. 02. 2022

\begin{definice}[Nezávislé jevy]
	Náhodné jevy $A$ a $B$ jsou nezávislé, pokud platí $P(A \cap B) = P(A)·P(B)$.
\end{definice}

\begin{upozorneni}
	Zase to nemá nic do činění s kauzalitou.
\end{upozorneni}

\begin{veta}
	Jsou-li dva jevy $A$ a $B$ nezávislé, pak jsou i jevy $A$ a $B^c$ nezávislé.

	Je-li navíc $P(B) > 0$, pak $P(A|B) = P(A)$.

	\begin{dukazin}
		$$ P(A \cap B^c) = P(A) - P(A \cap B) = P(A) - P(A)·P(B) = P(A)·(1 - P(B)) = P(A)·P(B). $$

		$$ P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)·P(B)}{P(B)} = P(A). $$
	\end{dukazin}
\end{veta}

\begin{definice}[Vzájemná nezávislost]
	Buď $\{A_\lambda\}_{\lambda \in \Lambda}$ systém náhodných jevů. Pak říkáme, že tyto jevy jsou (vzájemně) nezávislé, pokud pro každou konečnou množinu $I \subset \Lambda$ (dále $I \in ©F(\Lambda)$) platí $P(\bigcap_{i \in I} A_i) = \prod_{i \in I} P(A_i)$.
\end{definice}

\begin{veta}
	Buď $C = \{B_1, …, B_k\}$, $k \in ®N$, systém nezávislých jevů. Nahradíme-li libovolnou podmnožinu těchto jevů jejich doplňky, dostaneme opět systém nezávislých jevů

	\begin{dukazin}
		Indukcí podle velikosti nahrazované množiny. (Použije se předchozí věta.)
	\end{dukazin}
\end{veta}

\begin{veta}
	Jsou-li jevy $A_1, …, A_n, B_1, …, B_m$ vzájemně nezávislé a $P(B_1 \cap … \cap B_m) > 0$, pak
	$$ P(A_1 \cap … \cap A_n|B_1 \cap … \cap B_m) = P(A_1 \cap … \cap A_n) = P(A_1)·…·P(A_n). $$

	\begin{dukazin}
		Snadný.
	\end{dukazin}
\end{veta}

\section{Náhodné veličiny}
\begin{definice}[Náhodný element]
	Buďte $(\Omega, ©A)$ a $(\Omega', ©A')$ stavové prostory. Pak každé měřitelné zobrazení $X: \Omega \rightarrow \Omega'$ nazveme náhodný element z $\Omega'$.
\end{definice}

\begin{definice}[Náhodná veličina]
	Měřitelné zobrazení $X: (\Omega, ©A) \rightarrow (®R, ©B(®R))$ nazveme (reálnou) náhodnou veličinou.
\end{definice}

\begin{definice}[Značení]
	Místo $\{\omega \in \Omega | X(\omega) ≤ a\}$ píšeme $\{X ≤ a\}$, místo $P(\{X ≤ a\})$ píšeme $P(X ≤ a)$.
\end{definice}

\begin{definice}
	Buď $X$ náhodná veličina. $X^{-1}(©B(®R))$ značíme $\sigma(X)$ a nazýváme $\sigma$-algebrou náhodných jevů generovaných náhodnou veličinou $X$ ($\sigma$-algebra indukovaná $X$).
\end{definice}

% 23. 02. 2022

\begin{definice}[Rozdělení náhodné veličiny]
	Rozdělením náhodné veličiny $X: (\Omega, ©A) \rightarrow (®R, ©B)$ rozumíme indukovanou pravděpodobnostní míru $P_X$ na $(®R, ©B)$ definovanou jako
	$$ P_X(B) = P(\{\omega \in \Omega | X(\omega) \in B\}) = P(X^{-1}(B)), \qquad B \in ©B. $$

	\begin{poznamkain}[A důkaz, že je to pravděpodobnostní míra]
		$P_X$ je obraz míry $P$ v zobrazení $X$.
	\end{poznamkain}
\end{definice}

\begin{veta}[O přenosu integrace pro $P_X$]
	Buď $X$ náhodná veličina a buď $h$ měřitelná funkce $(®R, ©B) \rightarrow (®R, ©B)$. Pak platgí
	$$ \int_{\Omega} h(X(\omega)) d P(\omega) = \int_{®R} h(x) d P_X(x), $$
	pokud existuje alespoň jedna strana.

	\begin{dukazin}
		Speciální případ věty o obrazu míry z TMI1.
	\end{dukazin}
\end{veta}

\begin{definice}[Hustota náhodné veličiny]
	Buď $X$ náhodná veličina, $P_X$ její rozdělení a $\mu$ $\sigma$-konečná míra na $(®R, ©B)$ taková, že $P_X \ll \mu$. Potom $f(x) = \frac{d P_X}{d\mu}(x)$ se nazývá hustota náhodné veličiny $X$ vzhledem k míře $\mu$.

	\begin{poznamkain}
		$f(x)$ je určena jednoznačně $\mu$-skoro všude. Pokud pro $g: (®R, ©B) \rightarrow (®R, ©B)$ měřitelnou platí
		$$ \int_{®R} |g(x)| d P_X(x) < ∞ \qquad (\lor g(x) ≥ 0 \forall x), $$
		pak $\int_{®R} g(x) d P_X(x) = \int_{®R} g(x) f(x) d\mu(x)$.
	\end{poznamkain}
\end{definice}

\begin{veta}
	Buď $X$ náhodná veličina, pak platí následující rovnosti:
	$$ P(X \in B) := P(\{\omega \in \Omega | X(\omega) \in B\}) = \int_{\Omega} 1_B(X(\omega)) d P(\omega) = \int_{®R} 1_B(x) d P_X(x) = \int_{B} d P_X(x) = P_X(B) = $$
	$$ = \int_{®R} 1_B(x) d P_X(x) = \int_{®R} 1_B(x) f(x) d\mu(x) = \int_B f(x) d\mu(x). $$
	
	\begin{dukazin}
		Je to jen sesypání faktů, které už známe.
	\end{dukazin}
\end{veta}

\begin{definice}[Distribuční funkce]
	Mějme náhodnou veličinu $X: (\Omega, ©A) \rightarrow (®R, ©B)$. Funkci $F_X: ®R \rightarrow [0, 1]$ definovanou jako $F_X(x) = P(X ≤ x)$ nazveme distribuční funkce náhodné veličiny $X$.

	\begin{poznamkain}
		Definice se shoduje s distribuční funkcí z TMI1. (A tedy platí věta o vlastnostech distribuční funkce, s tím, že dokonce $\lim_{x \rightarrow +\infty} F_X(x) = 1$.)
	\end{poznamkain}
\end{definice}

\begin{veta}
	Buď $F: ®R \rightarrow ®R$ splňující vlastnosti distribuční funkce a $\lim_{x \rightarrow +∞} F_X(x) = 1$. Pak existuje pravděpodobnostní prostor $(\Omega, ©A, P)$ a náhodná veličina $X: (\Omega, ©A) \rightarrow (®R, ©B)$ taková, že $F_X = F$.

	\begin{dukazin}
		Z TMI1 víme, že existuje Lebesgueova-Stieltjesova míra $\mu$, jejíž distribuční funkce je $F$. Tj. $\mu(\(-∞, a\]) = F(a)$. Teď chybí jen dodefinovat $(\Omega, ©A, P)$ a $X$. Položíme $(\Omega, ©A, P) = (®R, ©B, \mu)$ a $X = \id_{®R}$.
	\end{dukazin}
\end{veta}

% 28. 02. 2022

\begin{definice}[Názvosloví: diskrétní náhodná veličina, absolutně spojitá veličina]
	Mějme diskrétní náhodnou veličinu $P_X ≡ \mu_d$, tj. existuje nejvýše spočetná $\{x_i\}_{i \in I} \subset ®R$ a $\{p_i\}_{i \in I} \subset \(0, 1\]$ takových, že $\sum_{i \in I} p_i = 1$ a platí $P_X = \sum_{i \in I} p_i \delta_{x_i}$.

	Potom nutně $F_X(x) = \sum_{i \in I} p_i 1_{[x, ∞)}(x)$ a také platí, že $P_X \ll \nu$, kde $\nu$ je čítací míra na $\{x_i\}_{i \in I}$.

	(Absolutně) spojitá náhodná veličina je taková, že $P_X = \mu_a \ll \lambda$, takže $P_X(B) \int_B f(x) d\mu$.
\end{definice}

\begin{definice}[Kvantilová funkce]
	Buď $F_X$ distribuční funkce náhodné veličiny $X$. Funkce $F^{-1}_X (u) = \int\{x | F_X(x) ≥ u\}$, $u \in (0, 1)$ se nazývá kvantilová funkce náhodné veličiny $X$.

	\begin{poznamkain}
		Bude potřeba později. Teď jen: Je neklesající a zleva spojitá. Lze z ní jednoznačně odvodit $F_X$.
	\end{poznamkain}
\end{definice}

\begin{upozorneni}
	Kvantilová funkce obecně není inverzní funkcí k $F_X$, protože inverzní funkce nemusí existovat. Ale pro $F_X$ rostoucí a spojitou je $F_X^{-1}$ inverzní funkcí k $F_X$.
\end{upozorneni}

\subsection{Střední hodnota, rozptyl a momenty náhodné veličiny}
\begin{definice}[Střední hodnota]
	Střední hodnota náhodné veličiny $X$ je číslo $®E X$ dané výrazem $®E X = \int_{\Omega} X(\omega) d P(\omega)$, pokud má integrál smysl.
\end{definice}

\begin{definice}[Medián]
	Medián rozdělení náhodné veličiny $X$ je číslo $q_{\frac{1}{2}}$ splňující $P(X ≤ q_{\frac{1}{2}}) ≥ \frac{1}{2}$ a $P(X ≥ q_{\frac{1}{2}}) ≥ \frac{1}{2}$.
\end{definice}

% 28. 02. 2022

\begin{veta}
	Buď $X$ náhodná veličina a $g: ®R \rightarrow ®R$ měřitelná funkce. Pak $g(X)$ je také náhodná veličina a $®E g(X) = \int_{®R} g(x) d P_X(x) = \int_{®R} g(x) dF_X(x)$, pokud alespoň jeden z výrazů existuje.

	\begin{dukazin}
		Složení 2 měřitelných funkcí je měřitelné, tj. $g(X)$ je opravdu náhodná veličina.
		$$ ®E g(X) = \int_{\Omega} g(X(\omega)) = d P(\omega) = \int_{®R} g(x) d P_X(x). $$
		Druhá rovnost plyne ze vztahu mezi $P_X$ a její distribuční funkcí.
	\end{dukazin}
\end{veta}

\begin{veta}[Základní vlastnosti $®E X$]
	Buďte $X, Y$ náhodné veličiny na stejném pravděpodobnostním prostoru $(\Omega, ©A, P)$. Pak platí
	$$ ®E(a + bX) = a + b ®E X,\qquad X \in L^1, a, b \in ®R, $$
	$$ ®E(X + Y) = ®E X + ®E Y, \qquad X, Y \in L^1, $$
	$$ P(X ≥ 0)  = 1 \implies ®E X ≥ 0, \qquad (\text{obecněji } P(X \in [a, b]) = 1 \implies ®E X \in [a, b]), $$
	$$ X \in L^1 \implies |X| \in L^1, $$
	$$ X ≤ Y, P\text{-skoro všude } \implies ®E X ≤ ®E Y (\text{pokud existují}). $$

	\begin{dukazin}
		Snadný, aplikace míry.
	\end{dukazin}
\end{veta}

\begin{definice}[Názvosloví: $P$-skoro jistě]
	$P$-skoro jistě znamená $P$-skoro všude.
\end{definice}

\begin{definice}[$n-tý$ moment]
	$n$-tý moment náhodné veličiny $X$ definujeme jako $®E X^n$, $n \in ®N$.

	$n$-tý absolutní moment náhodné veličiny $X$ definujeme jako $®E |X|^n$, $n \in ®N$.
	
	$n$-tý centrální moment náhodné veličiny $X$ definujeme jako $®E (X - ®E X)^n$, $n \in ®N$, pokud $®E X \in ®R$.
	
	$n$-tý absolutní centrální moment náhodné veličiny $X$ definujeme jako $®E |X - ®E X|^n$, $n \in ®N$, pokud $®E X \in ®R$.

	\begin{poznamkain}
		1-ní moment je $®E X$. První centrální moment je 0.
	\end{poznamkain}
\end{definice}

\begin{definice}[Rozptyl]
	Rozptyl náhodné veličiny $X$ je definován jako $®E(X - ®E X)^2$. Značí se $\var X$.

	\begin{poznamkain}
		Rozptyl je střední čtvercová odchylka $X$ od $®E X$. $\var X = ®E(X - ®E X)^2 ≥ 0$. $\var X = 0$ právě tehdy, když $X = ®E X$ skoro jistě.
	\end{poznamkain}
\end{definice}

\begin{veta}[Základní vlastnosti rozptylu]
	$$ \var(a + b X) = b^2 \var X, \qquad a, b \in ®R \land X \in L^2. $$

	\begin{dukazin}
		$$ \var(a + b X) = ®E(a + bX - ®E(a + b X))^2 = ®E(a + bX - a - b ®E^X) = ®E(b X - b ®E X) = ®E(b(X - ®E X))^2 = b^2 ®E(X - ®E X)^2 = b^2 \var X. $$
	\end{dukazin}
\end{veta}

\begin{veta}[Čebyševova nerovnost]
	Buď $X \in L^1$ náhodná veličina. Pak $P(|X - ®E X| ≥ a) ≤ \frac{\var X}{a^2}$, $\forall a > 0$.

	\begin{dukazin}
		Viz TMI1.
	\end{dukazin}
\end{veta}

\begin{definice}[Markovova nerovnost]
	Buď $X \in L^n$, $n \in ®N$, náhodná veličina. Pak $P(|X| ≥ a) ≤ \frac{®E |X|^n}{a^n}$, $\forall a > 0$.

	\begin{dukazin}
		Obdobně Čebyševově větě.
	\end{dukazin}
\end{definice}

\begin{veta}[Nerovnost mezi $L^p$ normami na pravděpodobnostních prostorech]
	Buď $X$ náhodná veličina, $0 < \alpha < \beta \in ®R$ a $®E |X|^\beta < ∞$. Pak platí $\sqrt[\alpha]{®E |X|^\alpha} ≤ \sqrt[\beta]{®E |X|^\beta}$, a speciálně tedy platí $®E |X| ≤ \sqrt{®E X^2}$.

	\begin{dukazin}
		$$ ®E |X|^\alpha = \int_{®R} |x|^\alpha d P_X(x) = \int_{®E} |x|^\alpha·1 d P_X(x) \overset{\text{Hölder na $p = \frac{\beta}{\alpha}$}} ≤ \(\int_{®R} |x|^\beta d P_X(x)\)^{\frac{\alpha}{\beta}}·\(\int_{®R} 1^q dP_X(x)\)^{\frac{1}{q}} = … · 1. $$
		(Integrál napravo je konečný z předpokladů této věty, tedy splňujeme předpoklady Höldera.) Odmocněním $\alpha$ dostáváme přesně chtěnou nerovnost.
	\end{dukazin}
\end{veta}

% 02. 03. 2022

\begin{priklady}[Absolutně spojitá rozdělení]
	Rovnoměrné rozdělení intervalu $[a, b]$, $a < b \in ®R$ značíme $R([a, b])$ a jeho hustota je až na konstantu Lebesgueova míra: $f_X(x) = \frac{1}{b - a}1_{(a, b)}(x)$.
	$$ F_X(t) = \begin{cases}0, & t ≤ a, \\ \frac{x - a}{b - a}, & t \in [a, b], \\ 1, & t ≥ b.\end{cases} \qquad ®E X = \int_a^b x · \frac{1}{b - a} d x = \frac{b + a}{2}, \var X = ®E X^2 - (®E X)^2 = \frac{(b - a)^2}{12}. $$

	Exponenciální rozdělení s parametrem $\lambda > 0$ značíme $Exp(\lambda)$. $P(X > t) = e^{-t \lambda}$, $t > 0$. $F_X(t) = P(X ≤ t) = 1 - e^{-\lambda t}$ pro $t ≥ 0$ a $0$ pro $t ≤ 0$. $f_X(x) = \lambda e^{-\lambda x}$, $x ≥ 0$ a $f_X(x) = 0$ jinak. $®E X = \frac{1}{\lambda}$, $\var X = \frac{1}{\lambda^2}$.

	\begin{poznamkain}
		Exponenciální rozdělení má vlastnost ztráty paměti, tedy že $P(X > s + t | X > s) = P(X > t)$, $s, t > 0$.
	\end{poznamkain}

	Normální (Gaussovo) rozdělení: Normované $N(0, 1)$ je $f_X(x) = \frac{1}{\sqrt{2 \pi}}e^{-\frac{x^2}{2}}$, $x \in ®R$. $F_X(t) = \int_{-∞}^t \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} dx$. Tyto $F_X$ a $f_X$ se často značí $\Phi$ a $\phi$. $®E X = 0$ ($x·\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$ je lichá funkce), $\var X = ®E(X - ®E X)^2 = ®E X^2 = 1$. $®E X^{2k + 1} = 0$.

	Obecné $N(\mu, \sigma^2)$, $\mu \in ®R$, $\sigma^2 > 0$ má $f_X(x) = \frac{1}{\sqrt{2 \pi \sigma^2}}·e^{-\frac{(x - \mu)^2}{2 \sigma^2}}$, $x \in ®R$.
\end{priklady}

\begin{tvrzeni}
	Buď $X$ nezáporná (tj. $P(X ≥ 0) = 1$) absolutně spojitá náhodná veličina, která splňuje $P(X > s + t | X > s) = P(X > t)$, $\forall s, t > 0$, pak $X \sim Exp$.

	\begin{dukazin}
		Dělat nebudeme.
	\end{dukazin}
\end{tvrzeni}

\begin{veta}
	$X \sim N(0, 1)$ a $Y := \sigma X + \mu$, pro $\sigma > 0$, $\mu \in ®R$. Pak $Y \sim N(\mu, \sigma^2)$.

	\begin{dukazin}
		TODO!!!
	\end{dukazin}
\end{veta}

\begin{dusledek}
	$$ F_Y(t) = P(Y ≤ t) = P(\sigma Z + x ≤ t) = P\(Z ≤ \frac{t - \mu}{\sigma}\) = \Phi\(\frac{t - \mu}{\sigma}\). $$
\end{dusledek}

\begin{dusledek}
	$$ ®E Y = ®E(\sigma Z + \mu) = \mu + \sigma ®E Z = \mu + 0 = \mu. $$
	$$ \var Y = \var(\sigma Z + \mu) = \sigma^2·\var Z = \sigma^2. $$
\end{dusledek}

\begin{veta}[Rozdělení funkce náhodné veličiny]
	Buď $X$ náhodná veličina s distribuční funkcí $F_X$, $g: ®R \rightarrow ®R$ měřitelná funkce. Pak $Y = g(X)$ je náhodná veličina s distribuční funkcí $F_Y(y) = \int_{\{x|g(x) ≤ Y\}} d F_X(x)$.

	\begin{dukazin}
		$$ F_Y(y) = P(Y ≤ y) = P(g(X) ≤ Y) = P_X(\{x | g(x) ≤ y\}) = \int_{\{x | g(x) ≤ y\}} d F_X(x). $$
	\end{dukazin}
\end{veta}

\end{document}
