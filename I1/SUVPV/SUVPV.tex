\documentclass[12pt]{article}					% Začátek dokumentu
\usepackage{../../MFFStyle}					    % Import stylu



\begin{document}
\section{Úvod}
    Bude se pracovat v Matlabu, v moodle je skupina.

% 7. 10. 2020

    \begin{poznamka}[Úkoly počítačového vidění]
        Detekovat, najít a určit věci (tváře, jestli se smějí, nádory, znaky jako znaky na SPZ, biometrika jako oko, tvář, podpis, budovy, lidi, auta, …) na obrázku
    \end{poznamka}

    \begin{poznamka}[Rozpoznávání objektu tradičním náhledem]
        pixely -> určení feature (např. rozdělení oblastí podle tvarů, důležitých bodů, barev, umístění hledaného objektu) expertem -> učení klasifikátoru -> rozpoznávání
    \end{poznamka}
    
    \begin{definice}[Feature vektor]
        Univerzální převedení obrázku do důležitých věcí.    

        Měl by být invariantní (měl by být stejný při rotaci a škálování), diskriminační (dobře rozdělovat objekty), kompaktní (co nejmenší)
    \end{definice}

    \begin{definice}[Rozpoznávání]
        Feature vektory tvoří prostor, kde se algoritmus naučí najít hranici, která odděluje objekty, co jsou nějaké a co jsou jinaké.
    \end{definice}

    \begin{poznamka}[Klasifikace může být za pomocí]
        Statistiky -- Bayesova teorie rozhodování

        Pravidel -- Rozhodovací strom

        Metriky -- Technika nejbližšího souseda, diskriminační analýza?, podpůrné vektorové stroje?

        Biologické inspirace -- Neuronové sítě
    \end{poznamka}

    \begin{definice}[Učení s učitelem]
        Na training setu víme správné odpovědi.
    \end{definice}

    \begin{definice}[Naivní Bayesův klasifikátor]
        Vychází z podmíněné pravděpodobnosti na základě věcí, co víme.
        \begin{prikladyin}
            Rozeznávání falešného úsměvu. 91,3\%.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Rozhodovací stromy]
        Pravidly určíme, kterou větví se vydáme. Výhodou je, že nepotřebujeme koncept vzdálenosti.
        \begin{prikladyin}
            Rozpoznávání, co se děje na videu (např. vražda). 70\% - 100\%.
        \end{prikladyin}
    \end{definice}
    
    \begin{definice}[K nejbližších sousedů]
        Podíváme se na nejbližší známé objekty a rozhodneme se podle nich.
        \begin{prikladyin}
            Čtení znaků. 99\% čísla, 94\% velká a 89\% malá písmena.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Lineární klasifikace]
        Rozdělení prostoru nadrovinou. Zlepšením je tzv. podpůrné vektorové stroje? (support vector machines)
        \begin{prikladyin}
            Rozpoznávání lidí a věku. 66,9 - 80\% lidi, 63,8 - 75,7\% věk.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Umělé neuronové sítě]
        Sítě z neuronů, které jsou velmi jednoduše simulovány, viz moje maturitní práce. (Na GitHubu pod uživatelem JoHavel).
        \begin{prikladyin}
            Rozpoznávání tváře. 90\%. (80\% na portrétech.)
        \end{prikladyin}
    \end{definice}

    \begin{poznamka}[Hluboké učení]
        pixely -> učení se včetně feature -> rozpoznávání

        \begin{prikladyin}
            AlexNet (top 5 error cca. 16\%)

            Každoročně se pořádá ILSVRC (Imagenet Large Scale Visual Recognition Challenge), kde už se dosáhlo méně než 4\% chyby (152 vrstev NN)…
        \end{prikladyin}
    \end{poznamka}

    \begin{poznamka}[Kombinovaný přístup]
        pixely -> featury nalezené NN -> trénování klasifikátoru -> rozpoznávání

        Hluboké učení se ale zdá účinnější.
    \end{poznamka}

% 12. 10. 2020 Vyučování nebylo z důvodu výpadku proudu

% 19. 10. 2020
    
    \begin{definice}[Klasifikační pipeline]
        Features -> {Výběr featur, jejich normalizace, …} -> klasifikace (výběr klasifikátoru, trénování klasifikátoru a následná klasifikace) -> evaluace -> features (respektive výstup, pokud jsme spokojeni).
    \end{definice}

    \begin{definice}[Features]
        Vlastnosti objektu, spojují nějakým způsobem podobné objekty. Musí být diskriminativní (pokud nejsou dostatečně diskriminativní, jakože často nejsou, dá se ještě hledat rozdělení s nejmenší chybou). Měly by být kompaktní (co nejmenší, protože s příliš featurami nelze ve stejném čase dostatečně naučit klasifikátor).
    \end{definice}

    \begin{definice}[Normalizace feature]
        Aby nenastával problém např. s odlišnými jednotkami, nebo s různě naškálovanými featury, normalizuje se vydělením referenční hodnotou, respektive různými statistickými metodami, např. standardizací $\(\tilde x_i = \frac{x_i - \mu}{\sigma}\)$, nebo $3\sigma$ škálováním $\(\tilde x_i = \frac{\frac{x_i - \mu}{3\sigma}+1}{2}\)$.
    \end{definice}

    \begin{poznamka}
        Rozhodovací stromy (a náhodné lesy), naivní bayesova metoda atd. nepotřebují normalizaci.
    \end{poznamka}

    \begin{definice}[Výběr featur]
        Některé featury můžou být totožné, některé zas redudantní.

        Takže vybereme nějakou podmnožinu featur a vyzkoušíme. Nebo se naopak podíváme na jednotlivé, ohodnotíme je a vybereme $K$ nejlepších. Další možnost je přidávat je po jedné a testovat je ne samotné, ale s již vybranými. Nebo můžeme začít se všemi a odstraňovat nejhorší (zase oběma způsoby, sekvenčním $1$ i jednokrokovým $K$ ). Existuje i kombinovaný, který udělá nejdříve jedno a pak druhé. Pak existují i genetické a další algoritmy.

        Podle čeho měřit: konzistence (jestli shodné hodnoty jsou ve shodné třídě, viz vzorec v prezentaci), nezávislost na ostatních featurách (opak tzv. korelace) + korelace s třídami, množství informace ($©I = -\log(P(A = a_i))$, $E(©I) = -\sum P(A = a)·\log_2(P(A=a))$), co nám dá, vzdálenost mezi třídami po použití dané featury, …
    \end{definice}

% 29. 10. 2020

    \begin{definice}[Transformace featur]
        Unsupervised (minimalizována je ztráta informací): Principal Component Analysis (PCA), Latent Semantic Indexing (LSI), Independent Component Analysis (ICA), …

        Supervised (maximalizuje se vzdálenost mezi třídami): Linear Discriminant Analysis (LDA), Canonical Correlation Analysis (CCA), Partial Least Squares (PLS), …
    \end{definice}

    \begin{definice}[PCA]
        Také Kaurhunen-Loeve (K-L) method. Hledá v rotacích a deformacích os největší varianci ($b_1^T \Sigma b_1$, kde $b_1$ je vektor projekce, $\Sigma$ je matice kovariance). Maximum se najde Lagrangeovy multiplikátory jako místo, kde $b^T_1 \Sigma b_1 = \lambda$, kde $\lambda$ je vlastní číslo $\Sigma$, je největší. Pro druhý vektor dostaneme totéž.

        $$ \Sigma = \frac{1}{N}XX^T (X =\text{ rozdíl od průměru}) $$ 
        $$ \Sigma b_j = \lambda b_j (b_j = \text{ vlastní vektory}) $$
        $$ X' = B^TX (B = \[b_j\])$$ 
    \end{definice}

    \begin{definice}[SVD (singular value decomposition)]
        Hledáme $USV^T$ tak, že $U$ a $V$ jsou vlastní vektory $A^TA$ a $AA^T$ a $V^T$ je poté diagonální matice vlastních čísel.

        $$ Y = \frac{1}{\sqrt{N}}X^T \implies Y^TY = \Sigma $$
        $$ Y = USV^T $$
        $$ V = \text{ vlastní čísla matice } Y^TY = \Sigma $$
    \end{definice}

    \begin{definice}[ICA]
        Báze nejsou kolmé. Je potřeba aby data byla nezávislá, tedy vycentrujeme odečtením průměru, a vyčistíme tím, že vynásobíme odmocninami vlastních čísel. Počítá se přes entropii (viz prezentace).
    \end{definice}

    \begin{poznamka}
        Unsupervised transformace featur může vést ke ztrátě oddělení tříd.
    \end{poznamka}

    \begin{definice}[LDA]
        Snažíme se dostat průměr každé třídy co nejdále od průměru všeho.

%        $\omega_j$ jsou prvky třídy $j$.
        Hodně vzorců, viz prezentace. Hledáme tolikarozměrnou projekční nadrovinu (v prezentaci její báze označena $w^T$), kolik máme tříd - 1. 
    \end{definice}

    \begin{poznamka}
        Lze použít nejdříve LDA, abychom snížili rozměry a následně použít LDA.
    \end{poznamka}

    \begin{poznamka}
        Na LDA potřebujeme hodně tréninkových dat. I při hodně dat jsou situace, kdy PCA je lepší (hlavně, když se třídy překrývají).
    \end{poznamka}

% 2. 11. 2020

    \begin{definice}[Rozhodovací hranice (decision boundaries)]
        Rozděluje prostor na jednotlivé třídy.

        Cílem je najít rozhodovací funkci, která bude správně přiřazovat třídy, nebo najít funkci rozumně definující hranice tříd.
    \end{definice}

    \begin{definice}[Pravděpodobnostní klasifikace]
        Mějme $M$ tříd  $\{\omega_i\}_{i=1}^M$. Potom pravděpodobnost, že objekt patří do třídy $\omega_i$, za předpokladu, že vektor je $¦x$, je
        $$ P(\omega_i|¦x) = \frac{P(¦x|\omega_i)·P(\omega_i)}{\sum_{j=1}^M P(¦x|\omega_j)·P(\omega_j)}. $$ 

        Objekt tedy zařadíme do nejpravděpodobnější třídy. Jelikož jmenovatel je všude stejný, tak počítáme
        $$ \omega_i, \text{, kde } i = \argmax_j P(¦x|\omega_j)·P(\omega_j). $$ 

        Hodí se zvláště, když matice kovariance je diagonální (třídy nejsou kovariantní).
    \end{definice}

    \begin{definice}[Naivní Bayesvův klasifikátor]
        Předpokládáme, že každá souřadnice feature vektoru je nezávislá:
        $$ P(x_1, x_2, …, x_D|\omega_i) = P(x_1|\omega_i) · P(x_2|\omega_i) · … · P(x_D|\omega_i). $$

        Tedy vytvoříme frekvenční tabulku tříd v závislosti na jednotlivých dimenzích a spočítáme pravděpodobnosti. Může se nám ale stát, že při mnoha dimenzích už bude násobení tolika pravděpodobností mimo přesnost, proto se používají logaritmy pravděpodobností.

        Navíc pokud nemáme dostatek dat, snadno se nám může (na „nespojité dimenzi“) stát, že pravděpodobnost nějaké třídy bude nula, tedy „přidáme“ 1 ke všem výskytům ve frekvenční tabulce.

        Abychom odhadli pravděpodobnost „spojité proměnné“, používáme standardní funkce hustoty, tedy např ($\overline{x}_{ij}$ je průměr vzorku, $\sigma^2_{ij}$ je variance vzorku): 
        $$ P(x_i = x|\omega_j) = \frac{1}{\sigma_{ij}\sqrt{2\pi}}e^{\frac{-(x-\overline{x}_{ij})}{2\sigma^2_{ij}}}. $$

        Pokud máme rozložení, kde jsou třeba 2 „hrby“, můžeme rozdělit prvky do „podtříd“ a rovnici výše doplnit o sumu a váhy, které se sečtou na 1 (GMM):
        $$ P(x_i = x|\omega_j) = \sum_{m}\frac{w_m}{\sigma_{ijm}\sqrt{2\pi}}e^{\frac{-(x-\overline{x}_{ijm})}{2\sigma^2_{ijm}}}. $$ 
        Na spočítání rozdělení do podtříd a vah se používá metoda EM (expectation, Maximization), kde se několikrát zopakuje rozdělení na základě aktuálních vah (v podstatě klasifikaci) a updatování průměru a variance.
    \end{definice}

% 9. 11. 2020

\section{Hodnocení klasifikátoru}
    \begin{definice}[Matice zaměňování - binární klasifikace]
        4 hodnoty TP, FN, FP, TN (True / False = klasifikováno správně nebo špatně, Positive / Negative = klasifikováno pozitivně nebo negativně).
        
        $ Accuracy = \frac{TP + TN}{P + N} $ má problém, když není dataset rovnoměrný (např. klasifikátor klasifikuje vždy negativně a v setu je jen 1 pozitivní, tak je accuracy 99\%). Místo toho lze použít $Error rate = 1 - Accuracy$ a jiné „rates“, např $Recall = \frac{TP}{P}$ a $Precision = \frac{TP}{TP + FP}$ (používají se pro sledování thresholdu v grafu křivky Recall -- Precision), $true positiv rate = TPR = \frac{TP}{P}$ a $FPR = \frac{FP}{N}$ (dohromady tzv. ROC křivka).
    \end{definice}

    \begin{definice}[F skore]
        Zkombinovaný recall a precision, má 1 parametr ($t$ je threshold)
        $$ F_\beta (t) = \frac{(1+\beta^2)p(t)r(t)}{r(t)+\beta^2p(t)}. $$

        Pro balancovaný model chceme maximalizovat $F_1$.
    \end{definice}

    \begin{definice}[Loss funkce]
        Znázorňuje cenu za špatné rozhodnutí.

        Zero-one loss je standardní loss funkce (1, když klasifikoval špatně, 0 když dobře).

    \end{definice}

% 16. 11. 2020

    \begin{definice}[Confidence Intervals]
        Když spočítáme chybu, tak můžeme ještě odhadnout skutečnou chybu jako
        $$ error(h|X) ± z_{1-\alpha/2}\sqrt{\frac{error(H|X) \(1-error(h|X)\)}{n}}, $$ 
        kde $z_{1-\alpha/2}$ je takzvaná kritická hodnota statistického rozložení, kterou najdeme v tabulkách (často se používá hodnota 1,960 odpovídající přesnosti 95\%).
    \end{definice}

\section{Testování}
    \begin{definice}
        Data rozdělujeme minimálně na 3 množiny: trénovací data (tréning), validovací data (nastavení parametrů) a testovací data (testování, MUSÍ být disjunktní s ostatními množinami).

        Pokud máme malou nebo nevyrovnanou množinu dat, rozdělení nemusí být reprezentativní, tedy se často generují podmnožiny tak, aby měli reprezentativní zastoupení tříd.
    \end{definice}

    \begin{definice}[Cross validace]
        Chyba se nepočítá na jedné množině testovacích dat, ale na mnoha jejích podmnožinách a dělá se průměr.

        Tyto podmnožiny dat můžeme získat buď náhodným výběrem (objekt může být zvolen vícekrát) nebo při tzv. K-fold cross validaci prostě rozdělit trénovací data na K shodně velkých podmnožin (ty zas nemají reprezentativní rozdělení v každé množině). Úprava Stratified K-fold cross validation vybírá K shodně velkých podmnožin, aby třídy byly zastoupeny reprezentativně, úprava „leave one out“ volí $K=N$.

        Nejčastěji se volí K=10, nebo pro velké sety K=3, nebo pro malé K=N.
    \end{definice}

    \begin{definice}[Bootstrap]
        Vybereme náhodně (klidně opakovaně) data na trénování a pak ty, co jsme nevybrali použijeme na testování. V trénovacích datech se objeví okolo 63,2\% dat.
    \end{definice}

\section{Porovnávání modelů}
    \begin{definice}[Porovnávání]
        Modely (někdy též hypotézy) můžeme porovnávat pomocí intervalu chyby, nebo třeba tzv. McNemarův test, kde se spočítají hodnoty kontingenční matice a následně se dosadí do vzorce.
    \end{definice}

\section{Další klasifikátory}
    \begin{definice}[K nejbližších sousedů]
        Pomocí bayesovy věty dojdeme k vzorci $p(\omega_i|¦x) = \frac{K_i}{K}$. Učení probíhá jednoduše, prostě si zapamatujeme data. Klasifikace probíhá také jednoduše, spočítáme nejbližších K objektů a klasifikujeme jako nejvíce zastoupenou třídu.

        Jediné, co můžeme nastavovat, je K (menší méně odhalí šum, ale má detailnější hranice, větší naopak přestává být senzitivní), a jakou metriku použijeme.

        Důležité je standardizovat data. Druhá možnost je použít vážených K nejbližších sousedů, kde každý soused (podle vzdálenosti) bude mít jinou váhu. Nebo (a to i v případě, že jsou souřadnice „deformovány jinak“) můžeme použít metriku s parametry a používat tzv. adaptivní nejbližší sousedé, kde v každé části prostoru bude metrika vypadat jinak.

        Kategorická data se pro K nejbližších sousedů buď musí převést na číselná, použít speciální metriky, nebo vektorizovat (na nuly a jedničky, dimenze pro každou kategorii).

        Data se dají trochu upravovat. Kromě normalizace ještě můžeme odstranit data, která by KNS klasifikoval „velmi“ špatně (mají hodně sousedů jiné třídy).
    \end{definice}

% 23. 11. 2020

    \subsection{Rozhodovací stromy}
    \begin{definice}[Rozhodovací stromy]
        Výhoda = nemusíme zavádět vzdálenosti (= můžeme klasifikovat i nominální data = data, u kterých nemá vzdálenost smysl).

        V každém nelistovém vrcholu (uzel) je tzv. test, větve reprezentují výsledky testu, v listech jsou klasifikační třídy.

        Bude nás zajímat, jaké všechny testy můžeme vykonat, jaký test je v každém uzlu použít a jestli je nutné ještě nějaký používat. Snažíme se snížit nečistot (množství tříd) podmnožin, na které dělíme v daném uzlu.

        Každý strom lze převést na binární, tedy budeme používat pouze binární rozhodovací stromy, tedy odpověď testu bude YES / NO. Většinou (v podstatě vždy) se ptáme jen na jeden příznak, protože vybírat a následně testovat podmnožinu je těžké.
    \end{definice}

    \begin{definice}[Měření „nečistosti“]
        Chceme, aby byla minimální, když obsahuje právě jednu třídu, naopak pokud každou třídu obsahuje ve stejném poměru a měla by být symetrická vůči výměně tříd.

        Optimalizaci stromu následně budeme dělat maximalizováním úbytku nečistosti (vážený průměr (přes velikosti) podmnožin ve větvích):
        $$ \Delta I(S, X_i) = I(S) - \sum_j \frac{|S_{ij}|}{|S|}I(S_{IJ}) $$ 

        Existuje několik takových funkcí, například Gini-index (jak moc často bude náhodný objekt špatně klasifikován, když klasifikujeme náhodně podle pravděpodobnost tříd):
        $$ p_i = \frac{|\{X|X \in \omega_i\}|}{|x_t|}, GI = \sum_{i = 1}^m p_i (1-p_i) $$

        Další možností je používat entropii (tzv. IG = information gained).
    \end{definice}

    \begin{definice}[Kdy prohlásit daný vrchol za list]
        Pokud nečistot je menší než nějaký threshold, pokud je velikost množiny dostatečně malá, pokud je vrchol čistý (moc velké stromy, tzv. přeučení $\implies$ nová data budou klasifikována špatně).

        Listu následně bude přiřazena třída, která: má maximální pravděpodobnost v dané množině (nejčastější kritérium), …
    \end{definice}

    \begin{priklady}
        Ukázáno na rozhodování, zda se bude něco hrát na základě počasí (teplota, vlhkost, vítr, …) s IG.
    \end{priklady}

    \begin{upozorneni}
        IG preferuje hodně hodnot, tedy buď musíme penalizovat rozdělení do více podmnožin (např. vydělením počtem podmnožin, pak zase ale favorizuje nebalancované rozdělení), nebo povolit pouze binární dělení (zkontrolujeme všechny možné dvojice, resp. všechny thresholdy = prahy, v případě číselných hodnot).
    \end{upozorneni}

    \begin{definice}[Ořezávání = pruning]
        Lze ořezávat za běhu (pre-pruning = když trénuji), nebo po přeučení (post-pruning).

        Metoda ořezáváni C4.5: veeeeeelký vzorec v prezentaci (spočítá zlepšení rozdělení = zmenšení vážené (velikostí podmnožin) chyby, když uděláme nejlepší test v daném uzlu, pokud se příliš nezmění, nedejbože zhorší, tak místo testu bude uzel list). 
    \end{definice}

    \begin{poznamka}[Plusy a mínusy]
        +: Jednoduché, málo přípravy dat, indikuje, co je nejlepší pro rozdělení.

        -: NP-úplný problém, pracuje špatně pro mnoho tříd, dlouhé učení, nebezpečí přeučení.
    \end{poznamka}

    \begin{definice}[Náhodný les (Breiman 2001)]
        Každý strom trénujeme na stejných datech, ale testy vybíráme z náhodné podmnožiny / příznak vyrobíme jako náhodnou kombinaci původních příznaků. Klasifikace pak probíhá, že uděláme klasifikaci podle každého stromu a vezmeme nejčastější.
    \end{definice}

    \subsection{Lineární klasifikátor}
        \begin{definice}[Lineární klasifikátor]
            Hledáme nadrovinu, která prostor rozdělí na 2 třídy (podmínkou je, že musí existovat / viz dále).

            Rovina je dána normálovým vektorem $¦w^T¦x + b = 0$. Rozhodování je pak dáno tím, zda je $¦w^T¦x + b$ kladné, nebo záporné. Často to uděláme tak, že přidáme dimenzi a rovina bude procházet počátkem. Dalším trikem je jednu třídu vynásobit $-1$ a následně máme jen jednu podmínku.

            Hledání lineárního klasifikátoru se dělá gradientovou metodou. Tedy iterativně: vybereme náhodný vektor a potom vždy spočítáme gradient účelové funkce, následně od vektoru odečteme learning rate krát gradient a opakujeme počítání gradientu a odčítání. Z taylorova rozvoje navíc můžeme najít přibližně nejlepší learning rate.
        \end{definice}

        \begin{definice}[Účelové funkce]
            Nejjednodušší je spočítat, kolik dat jsme klasifikovali špatně krát jak moc špatně $O_P = \sum_{z \in Z} - ¦u^T¦z$ ($Z$ je množina špatně klasifikovaných). Není spojitá, ale dá se použít. Takovéto funkci se říká Piece-wise…

            Aby byla spojitá, dá se použít tzv. kvadratická funkce $O_Q = \sum_{z \in Z}(¦u^T¦Z)^2$. Ta však často konverguje k tomu, že budou data přesně na hranici.
        \end{definice}

        \begin{definice}[Sekvenční učení]
            Pokud víme, že daná rovina existuje, tak vezmeme vektor a následně od něj budeme sekvenčně odečítat špatně klasifikované objekt.
        \end{definice}

% 7. 12. 2020

        TODO

        \begin{definice}[Metoda pomocných vektorů]
            Místo abychom hledali rozdělení prostoru nadrovinou, hledáme rozdělení „tlustou“ nadrovinou (budeme se snažit najít rozdělující rovinu tak, aby objekty byly od této roviny co nejdále).

            V metodě hladkých okrajů navíc budeme ignorovat špatně klasifikované objekty blízko (blízko nastavíme na validačních datech) nadroviny.
        \end{definice}

        \begin{definice}[Nelineární SVM]
            Převedeme data nějakým způsobem (např. na kužel při kruhových třídách) do vícerozměrného prostoru. Transformaci nemusíme hledat, hledáme jen jádro (skalární součin transformovaných dat). 

            Klasická jádra: Polynomické $K(x, y) = (a + x^Ty)^p$, gaussovská $K(x, y) = \exp\(-\frac{||x - y||^2}{2\sigma^2}\)$.
        \end{definice}

    \section{Kombinované modely (ensemble methods)}
        \begin{definice}
            Dá se kombinovat homogenně (stejný klasifikátor s různými parametry / daty / začátkem) nebo homogenně (různé klasifikátory).

            Dá se kombinovat průměrem, nebo hlasováním.
        \end{definice}

% 14. 12. 2020

        Prezentace, tohle jsem nějak nezvládl zapisovat. Ve zkratce, buď se můžou klasifikátory na ensemble trénovat úplně náhodně, nebo postupně s přidáním dat, na kterých se předchozí sekly, nebo se natrénují náhodně a následně se trénuje meta klasifikátor na jejich klasifikováních (bude z nich „vybírat“).

\section{Neuronové sítě}
    \begin{poznamka}[Historie]
        Už v roce 1943 McCulloch a Pitts vytvořili logický neuron, který měl práh, skokovou aktivační funkci a skupinu inhibitorů (stačil jediný inhibitor a výstup byl 0, tzv. absolutní inhibice) a skupinu excitorů, všude je signál pouze 0 / 1.

        Lze z nich složit libovolnou logickou funkci. Absolutní inhibice je navzájem záměnná s relativní inhibicí.
        
        Nelze tyto sítě učit, pouze modelovat, proto vznikl v roce 1949 Hebbianovo učení (síla spojení by měla být podle toho, jak spolu dané neurony souvisí).

        1957 Rosenblatt vytvořil tzv. perceptron (= lineární klasifikátor, jak jsme se ho učili), který fungoval až do roku 1969 (Golden Age), kdy Minsky ukázal, že jedním perceptronem nelze řešit neseparabilní data (XOR-problem). Pro více vrstvovou síť však neexistoval učící algoritmus (Dark Age = „AI Winter“).

        Ten byl vytvářen od 60. let, ale teprve od 80. byl zpopularizován. Tzv. backpropagation. Od roku 1995 existují Support Vector Machines, které umí totéž, ale jednodušeji. 2006 vznikla teorie Deep Neural Network, které se používají dodnes jako jeden z nejlepších modelů.
    \end{poznamka}

    \begin{definice}[Umělé neuronové sítě]
        My se budeme zabývat pouze tzv. feed forward topologií, která má vrstvy a hrany jdou pouze z vrstvy do další v pořadí.
    \end{definice}

% 21. 12. 2020

    \begin{poznamka}[Kdy přestat učit?]
        Nastavit maximální počet, nějaký cíl, nebo když dosáhneme minima chybové funkce, to však bude mít za následek overfitting, kterému ale můžeme předejít tím, že použijeme validační data a budeme sledovat chybovou funkci na nich (neznámých datech) místo testovacích.
    \end{poznamka}

    \begin{poznamka}
        Počet vrstev: 0 = lineární klasifikátor, 1 = z libovolného konečného prostoru do libovolného konečného, 2 = libovolná hranice v prostoru, ….
        
        Počet neuronů ve skryté vrstvě by měl být mezi počtem ve vstupní a počtem ve výstupní (nejvýše dvojnásobek výstupní), třeba 2/3 vstupní + výstupní.
    \end{poznamka}

    \begin{definice}[Konvoluční NN]
        Na každý „čtverec“ dat použijeme nějaký filtr, který z něho vypočítá 1 hodnotu. (Respektive z každé vrstvy filtru jednu hodnotu, tj např. $32 \times 32 \times 3 \overset{5\times 5\times 3}{\rightarrow} 30 \times 30 \times 3$.)

        Hodnoty mimo data můžeme doplnit, nebo používat filtr jen tam, kam se „vejde“. Používá se i tzv. stride = kde bude následující filtr.

        Na výsledky se ještě většinou použije ReLU ($f(x) = \max(0, x)$), nebo její modifikace Leaky ReLU, ELU, SReLu (aby se neztrácely záporné hodnoty);

        Konvoluční vrstvy se označují feature extraktor a dají se použít nejen s touto neuronovou sítí, ale můžeme použít (natrénovat na něm) tento extraktor s jiným klasifikátorem / nacvičit na nich jinou NN.
    \end{definice}

\section{Učení bez učitele}
    \begin{definice}[Clustering]
        Klasifikujeme na základě blízkosti ve feature space.

        Můžeme buď hierarchicky (do menších a menších množin), nebo nehierarchicky (jen na jednu skupinu tříd).

        Přístup sdola / shora = spojujeme prvky do množin / rozdělujeme množinu prvků na menší.

        Hard / soft = jeden objekt patří vždy do jedné třídy / jeden prvek může patřit do více tříd.
    \end{definice}

    \begin{definice}[Dendrogram]
        Graf („binární strom“) odpovídající hierarchii.
    \end{definice}

    \begin{definice}[Splitting Process of DIANA]
        Iterujeme: vybereme nejodlišnější objekt od ostatních, oddělíme ho a následně k němu přidáme ty objekty, které jsou v naší metrice blíže jemu než ostatním.
    \end{definice}

    \begin{definice}[Principal Directions Divise Partition]
        Zvolím osy dat jako při změně souřadnic a podle jedné z těchto os (té s „menším“ (ve smyslu projekce) průnikem s daty) to rozdělíme.

        Existují vylepšení, kde tu osu posunut tak, aby lépe oddělovala (xx|yyzz místo xxy|yzz).
    \end{definice}

    \begin{definice}[Median cut]
        Rozděluji v nejvíce variantní osu souřadnic, objekty rozdělím podle mediánu projekce na této osu.
    \end{definice}

    \begin{definice}[Agglomerative clustering]
        Spojování aktuálně nejbližších clusterů.

        Vzdálenost může být single-link (nejbližších prvků), complete-link (nejvzdálenějších), centroid-link (těžišť), average-link (průměrná vzdálenost).
    \end{definice}

    \begin{definice}[Ward's method]
        Spojování aktuálně nejmenší ceny za spojení (třeba podle počtu členů krát vzdálenost) clusterů. Například:
        $$ MergeCost(A, B) = \frac{N_A·N_B}{N_A + N_B}·d(A, B) $$ 
    \end{definice}

    \begin{definice}[Iterative shrinking]
            Iterujeme: vybereme shluk „nejlevnější“ (třeba jako v předchozím algoritmu) na rozdrobení (= rozdělíme tento shluk mezi okolní) a rozdrobíme.
    \end{definice}

% 4. 1. 2021

    \begin{definice}[Algoritmus K-průměrů]
        Nehierarchický. Vybereme náhodně $K$ bodů v prostoru. Následně data přiřadíme nejbližšímu takovému bodu. Následně posuneme těch $K$ bodů, aby byly těžiště k nim přiřazených bodů. Následně opakujeme přiřazení a posunutí, dokud nedosáhneme nějakého „stop“ kritéria.

        Vždy zkonverguje k lokálnímu optimu, ale optimum nemusí být globální. Je citlivý na šum a body daleko. Klustery jsou závislé na začátečním rozložení $K$ bodů, tedy není to deterministický algoritmus.

        Můžeme používat i tzv. medoidy (v podstatě mediány), pak jsou $K$ body z množiny, nebo mediány (ve všech složkách), pak jsou alespoň jejich složky z množiny.
    \end{definice}

    \begin{definice}[SOM]
        Náhodně se vyberou váhy mapy (neuronové sítě, která má jako vstup vektor a výstup mřížku -> každý bod má (učenou) souřadnici (ve vahách neuronové sítě) v původním prostoru a zároveň pevné umístění v mřížce $®Z^2$ resp. $®Z^3$, ). Pro učení opakujeme: Vložíme vektor a posuneme nejbližší neuron výsledek směrem ke vstupu…
    \end{definice}

    \begin{poznamka}
        Dále jsme probírali automaty a gramatiky, ale to nebude u zkoušky.
    \end{poznamka}

\end{document}
