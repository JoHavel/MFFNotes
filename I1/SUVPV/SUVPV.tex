\documentclass[12pt]{article}					% Začátek dokumentu
\usepackage{../../MFFStyle}					    % Import stylu



\begin{document}
\section{Úvod}
    Bude se pracovat v Matlabu, v moodle je skupina.

% 7. 10. 2020

    \begin{poznamka}[Úkoly počítačového vidění]
        Detekovat, najít a určit věci (tváře, jestli se smějí, nádory, znaky jako znaky na SPZ, biometrika jako oko, tvář, podpis, budovy, lidi, auta, …) na obrázku
    \end{poznamka}

    \begin{poznamka}[Rozpoznávání objektu tradičním náhledem]
        pixely -> určení feature (např. rozdělení oblastí podle tvarů, důležitých bodů, barev, umístění hledaného objektu) expertem -> učení klasifikátoru -> rozpoznávání
    \end{poznamka}
    
    \begin{definice}[Feature vektor]
        Univerzální převedení obrázku do důležitých věcí.    

        Měl by být invariantní (měl by být stejný při rotaci a škálování), diskriminační (dobře rozdělovat objekty), kompaktní (co nejmenší)
    \end{definice}

    \begin{definice}[Rozpoznávání]
        Feature vektory tvoří prostor, kde se algoritmus naučí najít hranici, která odděluje objekty, co jsou nějaké a co jsou jinaké.
    \end{definice}

    \begin{poznamka}[Klasifikace může být za pomocí]
        Statistiky -- Bayesova teorie rozhodování

        Pravidel -- Rozhodovací strom

        Metriky -- Technika nejbližšího souseda, diskriminační analýza?, podpůrné vektorové stroje?

        Biologické inspirace -- Neuronové sítě
    \end{poznamka}

    \begin{definice}[Učení s učitelem]
        Na training setu víme správné odpovědi.
    \end{definice}

    \begin{definice}[Naivní Bayesův klasifikátor]
        Vychází z podmíněné pravděpodobnosti na základě věcí, co víme.
        \begin{prikladyin}
            Rozeznávání falešného úsměvu. 91,3\%.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Rozhodovací stromy]
        Pravidly určíme, kterou větví se vydáme. Výhodou je, že nepotřebujeme koncept vzdálenosti.
        \begin{prikladyin}
            Rozpoznávání, co se děje na videu (např. vražda). 70\% - 100\%.
        \end{prikladyin}
    \end{definice}
    
    \begin{definice}[K nejbližších sousedů]
        Podíváme se na nejbližší známé objekty a rozhodneme se podle nich.
        \begin{prikladyin}
            Čtení znaků. 99\% čísla, 94\% velká a 89\% malá písmena.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Lineární klasifikace]
        Rozdělení prostoru nadrovinou. Zlepšením je tzv. podpůrné vektorové stroje? (support vector machines)
        \begin{prikladyin}
            Rozpoznávání lidí a věku. 66,9 - 80\% lidi, 63,8 - 75,7\% věk.
        \end{prikladyin}
    \end{definice}

    \begin{definice}[Umělé neuronové sítě]
        Sítě z neuronů, které jsou velmi jednoduše simulovány, viz moje maturitní práce. (Na GitHubu pod uživatelem JoHavel).
        \begin{prikladyin}
            Rozpoznávání tváře. 90\%. (80\% na portrétech.)
        \end{prikladyin}
    \end{definice}

    \begin{poznamka}[Hluboké učení]
        pixely -> učení se včetně feature -> rozpoznávání

        \begin{prikladyin}
            AlexNet (top 5 error cca. 16\%)

            Každoročně se pořádá ILSVRC (Imagenet Large Scale Visual Recognition Challenge), kde už se dosáhlo méně než 4\% chyby (152 vrstev NN)…
        \end{prikladyin}
    \end{poznamka}

    \begin{poznamka}[Kombinovaný přístup]
        pixely -> featury nalezené NN -> trénování klasifikátoru -> rozpoznávání

        Hluboké učení se ale zdá účinnější.
    \end{poznamka}

% 12. 10. 2020 Vyučování nebylo z důvodu výpadku proudu

% 19. 10. 2020
    
    \begin{definice}[Klasifikační pipeline]
        Features -> {Výběr featur, jejich normalizace, …} -> klasifikace (výběr klasifikátoru, trénování klasifikátoru a následná klasifikace) -> evaluace -> features (respektive výstup, pokud jsme spokojeni).
    \end{definice}

    \begin{definice}[Features]
        Vlastnosti objektu, spojují nějakým způsobem podobné objekty. Musí být diskriminativní (pokud nejsou dostatečně diskriminativní, jakože často nejsou, dá se ještě hledat rozdělení s nejmenší chybou). Měly by být kompaktní (co nejmenší, protože s příliš featurami nelze ve stejném čase dostatečně naučit klasifikátor).
    \end{definice}

    \begin{definice}[Normalizace feature]
        Aby nenastával problém např. s odlišnými jednotkami, nebo s různě naškálovanými featury, normalizuje se vydělením referenční hodnotou, respektive různými statistickými metodami, např. standardizací $\(\tilde x_i = \frac{x_i - \mu}{\sigma}\)$, nebo $3\sigma$ škálováním $\(\tilde x_i = \frac{\frac{x_i - \mu}{3\sigma}+1}{2}\)$.
    \end{definice}

    \begin{poznamka}
        Rozhodovací stromy (a náhodné lesy), naivní bayesova metoda atd. nepotřebují normalizaci.
    \end{poznamka}

    \begin{definice}[Výběr featur]
        Některé featury můžou být totožné, některé zas redudantní.

        Takže vybereme nějakou podmnožinu featur a vyzkoušíme. Nebo se naopak podíváme na jednotlivé, ohodnotíme je a vybereme $K$ nejlepších. Další možnost je přidávat je po jedné a testovat je ne samotné, ale s již vybranými. Nebo můžeme začít se všemi a odstraňovat nejhorší (zase oběma způsoby, sekvenčním $1$ i jednokrokovým $K$ ). Existuje i kombinovaný, který udělá nejdříve jedno a pak druhé. Pak existují i genetické a další algoritmy.

        Podle čeho měřit: konzistence (jestli shodné hodnoty jsou ve shodné třídě, viz vzorec v prezentaci), nezávislost na ostatních featurách (opak tzv. korelace) + korelace s třídami, množství informace ($©I = -\log(P(A = a_i))$, $E(©I) = -\sum P(A = a)·\log_2(P(A=a))$), co nám dá, vzdálenost mezi třídami po použití dané featury, …
    \end{definice}

% 29. 10. 2020

    \begin{definice}[Transformace featur]
        Unsupervised (minimalizována je ztráta informací): Principal Component Analysis (PCA), Latent Semantic Indexing (LSI), Independent Component Analysis (ICA), …

        Supervised (maximalizuje se vzdálenost mezi třídami): Linear Discriminant Analysis (LDA), Canonical Correlation Analysis (CCA), Partial Least Squares (PLS), …
    \end{definice}

    \begin{definice}[PCA]
        Také Kaurhunen-Loeve (K-L) method. Hledá v rotacích a deformacích os největší varianci ($b_1^T \Sigma b_1$, kde $b_1$ je vektor projekce, $\Sigma$ je matice kovariance). Maximum se najde Lagrangeovy multiplikátory jako místo, kde $b^T_1 \Sigma b_1 = \lambda$, kde $\lambda$ je vlastní číslo $\Sigma$, je největší. Pro druhý vektor dostaneme totéž.

        $$ \Sigma = \frac{1}{N}XX^T (X =\text{ rozdíl od průměru}) $$ 
        $$ \Sigma b_j = \lambda b_j (b_j = \text{ vlastní vektory}) $$
        $$ X' = B^TX (B = \[b_j\])$$ 
    \end{definice}

    \begin{definice}[SVD (singular value decomposition)]
        Hledáme $USV^T$ tak, že $U$ a $V$ jsou vlastní vektory $A^TA$ a $AA^T$ a $V^T$ je poté diagonální matice vlastních čísel.

        $$ Y = \frac{1}{\sqrt{N}}X^T \implies Y^TY = \Sigma $$
        $$ Y = USV^T $$
        $$ V = \text{ vlastní čísla matice } Y^TY = \Sigma $$
    \end{definice}

    \begin{definice}[ICA]
        Báze nejsou kolmé. Je potřeba aby data byla nezávislá, tedy vycentrujeme odečtením průměru, a vyčistíme tím, že vynásobíme odmocninami vlastních čísel. Počítá se přes entropii (viz prezentace).
    \end{definice}

    \begin{poznamka}
        Unsupervised transformace featur může vést ke ztrátě oddělení tříd.
    \end{poznamka}

    \begin{definice}[LDA]
        Snažíme se dostat průměr každé třídy co nejdále od průměru všeho.

%        $\omega_j$ jsou prvky třídy $j$.
        Hodně vzorců, viz prezentace. Hledáme tolikarozměrnou projekční nadrovinu (v prezentaci její báze označena $w^T$), kolik máme tříd - 1. 
    \end{definice}

    \begin{poznamka}
        Lze použít nejdříve LDA, abychom snížili rozměry a následně použít LDA.
    \end{poznamka}

    \begin{poznamka}
        Na LDA potřebujeme hodně tréninkových dat. I při hodně dat jsou situace, kdy PCA je lepší (hlavně, když se třídy překrývají).
    \end{poznamka}

% 2. 11. 2020

    \begin{definice}[Rozhodovací hranice (decision boundaries)]
        Rozděluje prostor na jednotlivé třídy.

        Cílem je najít rozhodovací funkci, která bude správně přiřazovat třídy, nebo najít funkci rozumně definující hranice tříd.
    \end{definice}

    \begin{definice}[Pravděpodobnostní klasifikace]
        Mějme $M$ tříd  $\{\omega_i\}_{i=1}^M$. Potom pravděpodobnost, že objekt patří do třídy $\omega_i$, za předpokladu, že vektor je $¦x$, je
        $$ P(\omega_i|¦x) = \frac{P(¦x|\omega_i)·P(\omega_i)}{\sum_{j=1}^M P(¦x|\omega_j)·P(\omega_j)}. $$ 

        Objekt tedy zařadíme do nejpravděpodobnější třídy. Jelikož jmenovatel je všude stejný, tak počítáme
        $$ \omega_i, \text{, kde } i = \argmax_j P(¦x|\omega_j)·P(\omega_j). $$ 

        Hodí se zvláště, když matice kovariance je diagonální (třídy nejsou kovariantní).
    \end{definice}

    \begin{definice}[Naivní Bayesvův klasifikátor]
        Předpokládáme, že každá souřadnice feature vektoru je nezávislá:
        $$ P(x_1, x_2, …, x_D|\omega_i) = P(x_1|\omega_i) · P(x_2|\omega_i) · … · P(x_D|\omega_i). $$

        Tedy vytvoříme frekvenční tabulku tříd v závislosti na jednotlivých dimenzích a spočítáme pravděpodobnosti. Může se nám ale stát, že při mnoha dimenzích už bude násobení tolika pravděpodobností mimo přesnost, proto se používají logaritmy pravděpodobností.

        Navíc pokud nemáme dostatek dat, snadno se nám může (na „nespojité dimenzi“) stát, že pravděpodobnost nějaké třídy bude nula, tedy „přidáme“ 1 ke všem výskytům ve frekvenční tabulce.

        Abychom odhadli pravděpodobnost „spojité proměnné“, používáme standardní funkce hustoty, tedy např ($\overline{x}_{ij}$ je průměr vzorku, $\sigma^2_{ij}$ je variance vzorku): 
        $$ P(x_i = x|\omega_j) = \frac{1}{\sigma_{ij}\sqrt{2\pi}}e^{\frac{-(x-\overline{x}_{ij})}{2\sigma^2_{ij}}}. $$

        Pokud máme rozložení, kde jsou třeba 2 „hrby“, můžeme rozdělit prvky do „podtříd“ a rovnici výše doplnit o sumu a váhy, které se sečtou na 1 (GMM):
        $$ P(x_i = x|\omega_j) = \sum_{m}\frac{w_m}{\sigma_{ijm}\sqrt{2\pi}}e^{\frac{-(x-\overline{x}_{ijm})}{2\sigma^2_{ijm}}}. $$ 
        Na spočítání rozdělení do podtříd a vah se používá metoda EM (expectation, Maximization), kde se několikrát zopakuje rozdělení na základě aktuálních vah (v podstatě klasifikaci) a updatování průměru a variance.
    \end{definice}

% 9. 11. 2020

\section{Hodnocení klasifikátoru}
    \begin{definice}[Matice zaměňování - binární klasifikace]
        4 hodnoty TP, FN, FP, TN (True / False = klasifikováno správně nebo špatně, Positive / Negative = klasifikováno pozitivně nebo negativně).
        
        $ Accuracy = \frac{TP + TN}{P + N} $ má problém, když není dataset rovnoměrný (např. klasifikátor klasifikuje vždy negativně a v setu je jen 1 pozitivní, tak je accuracy 99\%). Místo toho lze použít $Error rate = 1 - Accuracy$ a jiné „rates“, např $Recall = \frac{TP}{P}$ a $Precision = \frac{TP}{TP + FP}$ (používají se pro sledování thresholdu v grafu křivky Recall -- Precision), $true positiv rate = TPR = \frac{TP}{P}$ a $FPR = \frac{FP}{N}$ (dohromady tzv. ROC křivka).
    \end{definice}

    \begin{definice}[F skore]
        Zkombinovaný recall a precision, má 1 parametr ($t$ je threshold)
        $$ F_\beta (t) = \frac{(1+\beta^2)p(t)r(t)}{r(t)+\beta^2p(t)}. $$

        Pro balancovaný model chceme maximalizovat $F_1$.
    \end{definice}

    \begin{definice}[Loss funkce]
        Znázorňuje cenu za špatné rozhodnutí.

        Zero-one loss je standardní loss funkce (1, když klasifikoval špatně, 0 když dobře).

    \end{definice}

\end{document}
